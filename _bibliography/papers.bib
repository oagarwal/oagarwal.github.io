---
---

@inproceedings{agarwal-nenkova-2023-named,
    title = "Named Entity Recognition in a Very Homogenous Domain",
    author = "Agarwal, Oshin  and
      Nenkova, Ani",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2023",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-eacl.138",
    pages = "1805--1810",
    abstract = "Machine Learning models have lower accuracy when tested on out-of-domain data. Developing models that perform well on several domains or can be quickly adapted to a new domain is an important research area. Domain, however, is a vague term, that can refer to any aspect of data such as language, genre, source and structure. We consider a very homogeneous source of data, specifically sentences from news articles from the same newspaper in English, and collect a dataset of such {``}in-domain{''} sentences annotated with named entities. We find that even in such a homogeneous domain, the performance of named entity recognition models varies significantly across news topics. Selection of diverse data, as we demonstrate, is crucial even in a seemingly homogeneous domain.",
}


@article{agarwal-nenkova-2022-temporal,
    title = "Temporal Effects on Pre-trained Models for Language Processing Tasks",
    author = "Agarwal, Oshin  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "10",
    year = "2022",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2022.tacl-1.53",
    doi = "10.1162/tacl_a_00497",
    pages = "904--921",
    abstract = "Keeping the performance of language technologies optimal as time passes is of great practical interest. We study temporal effects on model performance on downstream language tasks, establishing a nuanced terminology for such discussion and identifying factors essential to conduct a robust study. We present experiments for several tasks in English where the label correctness is not dependent on time and demonstrate the importance of distinguishing between temporal model deterioration and temporal domain adaptation for systems using pre-trained representations. We find that, depending on the task, temporal model deterioration is not necessarily a concern. Temporal domain adaptation, however, is beneficial in all cases, with better performance for a given time period possible when the system is trained on temporally more recent data. Therefore, we also examine the efficacy of two approaches for temporal domain adaptation without human annotations on new data. Self-labeling shows consistent improvement and notably, for named entity recognition, leads to better temporal adaptation than even human annotations.",
    selected=true,
}


@inproceedings{hede-etal-2021-toxicity,
    title = "From Toxicity in Online Comments to Incivility in {A}merican News: Proceed with Caution",
    author = "Hede, Anushree  and
      Agarwal, Oshin  and
      Lu, Linda  and
      Mutz, Diana C.  and
      Nenkova, Ani",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.225",
    doi = "10.18653/v1/2021.eacl-main.225",
    pages = "2620--2630",
    abstract = "The ability to quantify incivility online, in news and in congressional debates is of great interest to political scientists. Computational tools for detecting online incivility for English are now fairly accessible and potentially could be applied more broadly. We test the Jigsaw Perspective API for its ability to detect the degree of incivility on a corpus that we developed, consisting of manual annotations of civility in American news. We demonstrate that toxicity models, as exemplified by Perspective, are inadequate for the analysis of incivility in news. We carry out error analysis that points to the need to develop methods to remove spurious correlations between words often mentioned in the news, especially identity descriptors and incivility. Without such improvements, applying Perspective or similar models on news is likely to lead to wrong conclusions, that are not aligned with the human perception of incivility.",
}


@article{agarwal-etal-2021-interpretability,
    title = "Interpretability Analysis for Named Entity Recognition to Understand System Predictions and How They Can Improve",
    author = "Agarwal, Oshin  and
      Yang, Yinfei  and
      Wallace, Byron C.  and
      Nenkova, Ani",
    journal = "Computational Linguistics",
    volume = "47",
    number = "1",
    month = mar,
    year = "2021",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2021.cl-1.5",
    doi = "10.1162/coli_a_00397",
    pages = "117--140",
    abstract = "Abstract Named entity recognition systems achieve remarkable performance on domains such as English news. It is natural to ask: What are these models actually learning to achieve this? Are they merely memorizing the names themselves? Or are they capable of interpreting the text and inferring the correct entity type from the linguistic context? We examine these questions by contrasting the performance of several variants of architectures for named entity recognition, with some provided only representations of the context as features. We experiment with GloVe-based BiLSTM-CRF as well as BERT. We find that context does influence predictions, but the main factor driving high performance is learning the named tokens themselves. Furthermore, we find that BERT is not always better at recognizing predictive contexts compared to a BiLSTM-CRF model. We enlist human annotators to evaluate the feasibility of inferring entity types from context alone and find that humans are also mostly unable to infer entity types for the majority of examples on which the context-only system made errors. However, there is room for improvement: A system should be able to recognize any named entity in a predictive context correctly and our experiments indicate that current systems may be improved by such capability. Our human study also revealed that systems and humans do not always learn the same contextual clues, and context-only systems are sometimes correct even when humans fail to recognize the entity type from the context. Finally, we find that one issue contributing to model errors is the use of {``}entangled{''} representations that encode both contextual and local token information into a single vector, which can obscure clues. Our results suggest that designing models that explicitly operate over representations of local inputs and context, respectively, may in some cases improve performance. In light of these and related findings, we highlight directions for future work.",
    selected=true,
}


@inproceedings{agarwal-etal-2021-knowledge,
    title = "Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced Language Model Pre-training",
    author = "Agarwal, Oshin  and
      Ge, Heming  and
      Shakeri, Siamak  and
      Al-Rfou, Rami",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.278",
    doi = "10.18653/v1/2021.naacl-main.278",
    pages = "3554--3565",
    abstract = "Prior work on Data-To-Text Generation, the task of converting knowledge graph (KG) triples into natural text, focused on domain-specific benchmark datasets. In this paper, however, we verbalize the entire English Wikidata KG, and discuss the unique challenges associated with a broad, open-domain, large-scale verbalization. We further show that verbalizing a comprehensive, encyclopedic KG like Wikidata can be used to integrate structured KGs and natural language corpora. In contrast to the many architectures that have been developed to integrate these two sources, our approach converts the KG into natural text, allowing it to be seamlessly integrated into existing language models. It carries the further advantages of improved factual accuracy and reduced toxicity in the resulting language model. We evaluate this approach by augmenting the retrieval corpus in a retrieval language model and showing significant improvements on the knowledge intensive tasks of open domain QA and the LAMA knowledge probe.",
    selected=true,
}


@inproceedings{agarwal-nenkova-2021-utility,
    title = "The Utility and Interplay of Gazetteers and Entity Segmentation for Named Entity Recognition in {E}nglish",
    author = "Agarwal, Oshin  and
      Nenkova, Ani",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.349",
    doi = "10.18653/v1/2021.findings-acl.349",
    pages = "3990--4002",
}


@inproceedings{agarwal-etal-2020-machine,
    title = "Machine Translation Aided Bilingual Data-to-Text Generation and Semantic Parsing",
    author = "Agarwal, Oshin  and
      Kale, Mihir  and
      Ge, Heming  and
      Shakeri, Siamak  and
      Al-Rfou, Rami",
    booktitle = "Proceedings of the 3rd International Workshop on Natural Language Generation from the Semantic Web (WebNLG+)",
    month = "12",
    year = "2020",
    address = "Dublin, Ireland (Virtual)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.webnlg-1.13",
    pages = "125--130",
    abstract = "We present a system for bilingual Data-ToText Generation and Semantic Parsing. We use a text-to-text generator to learn a single model that works for both languages on each of the tasks. The model is aided by machine translation during both pre-training and fine-tuning. We evaluate the system on WebNLG 2020 data 1 , which consists of RDF triples in English and natural language sentences in English and Russian for both the tasks. We achieve considerable gains over monolingual models, especially on unseen relations and Russian.",
}


@inproceedings{parikh-etal-2019-browsing,
    title = "Browsing Health: Information Extraction to Support New Interfaces for Accessing Medical Evidence",
    author = "Parikh, Soham  and
      Conrad, Elizabeth  and
      Agarwal, Oshin  and
      Marshall, Iain  and
      Wallace, Byron  and
      Nenkova, Ani",
    booktitle = "Proceedings of the Workshop on Extracting Structured Knowledge from Scientific Publications",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-2606",
    doi = "10.18653/v1/W19-2606",
    pages = "43--47",
    abstract = "Standard paradigms for search do not work well in the medical context. Typical information needs, such as retrieving a full list of medical interventions for a given condition, or finding the reported efficacy of a particular treatment with respect to a specific outcome of interest cannot be straightforwardly posed in typical text-box search. Instead, we propose faceted-search in which a user specifies a condition and then can browse treatments and outcomes that have been evaluated. Choosing from these, they can access randomized control trials (RCTs) describing individual studies. Realizing such a view of the medical evidence requires information extraction techniques to identify the population, interventions, and outcome measures in an RCT. Patients, health practitioners, and biomedical librarians all stand to benefit from such innovation in search of medical evidence. We present an initial prototype of such an interface applied to pre-registered clinical studies. We also discuss pilot studies into the applicability of information extraction methods to allow for similar access to all published trial results.",
}


@inproceedings{agarwal-etal-2019-evaluation,
    title = "Evaluation of named entity coreference",
    author = "Agarwal, Oshin  and
      Subramanian, Sanjay  and
      Nenkova, Ani  and
      Roth, Dan",
    booktitle = "Proceedings of the Second Workshop on Computational Models of Reference, Anaphora and Coreference",
    month = jun,
    year = "2019",
    address = "Minneapolis, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-2801",
    doi = "10.18653/v1/W19-2801",
    pages = "1--7",
    abstract = "In many NLP applications like search and information extraction for named entities, it is necessary to find all the mentions of a named entity, some of which appear as pronouns (she, his, etc.) or nominals (the professor, the German chancellor, etc.). It is therefore important that coreference resolution systems are able to link these different types of mentions to the correct entity name. We evaluate state-of-the-art coreference resolution systems for the task of resolving all mentions to named entities. Our analysis reveals that standard coreference metrics do not reflect adequately the requirements in this task: they do not penalize systems for not identifying any mentions by name to an entity and they reward systems even if systems find correctly mentions to the same entity but fail to link these to a proper name (she{--}the student{--}no name). We introduce new metrics for evaluating named entity coreference that address these discrepancies and show that for the comparisons of competitive systems, standard coreference evaluations could give misleading results for this task. We are, however, able to confirm that the state-of-the art system according to traditional evaluations also performs vastly better than other systems on the named entity coreference task.",
}


@inproceedings{yang-etal-2019-predicting,
    title = "Predicting Annotation Difficulty to Improve Task Routing and Model Performance for Biomedical Information Extraction",
    author = "Yang, Yinfei  and
      Agarwal, Oshin  and
      Tar, Chris  and
      Wallace, Byron C.  and
      Nenkova, Ani",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1150",
    doi = "10.18653/v1/N19-1150",
    pages = "1471--1480",
    abstract = "Modern NLP systems require high-quality annotated data. For specialized domains, expert annotations may be prohibitively expensive; the alternative is to rely on crowdsourcing to reduce costs at the risk of introducing noise. In this paper we demonstrate that directly modeling instance difficulty can be used to improve model performance and to route instances to appropriate annotators. Our difficulty prediction model combines two learned representations: a {`}universal{'} encoder trained on out of domain data, and a task-specific encoder. Experiments on a complex biomedical information extraction task using expert and lay annotators show that: (i) simply excluding from the training data instances predicted to be difficult yields a small boost in performance; (ii) using difficulty scores to weight instances during training provides further, consistent gains; (iii) assigning instances predicted to be difficult to domain experts is an effective strategy for task routing. Further, our experiments confirm the expectation that for such domain-specific tasks expert annotations are of much higher quality and preferable to obtain if practical and that augmenting small amounts of expert data with a larger set of lay annotations leads to further improvements in model performance.",
}


@inproceedings{agarwal-etal-2019-word,
    title = "Word Embeddings (Also) Encode Human Personality Stereotypes",
    author = "Agarwal, Oshin  and
      Durup{\i}nar, Funda  and
      Badler, Norman I.  and
      Nenkova, Ani",
    booktitle = "Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*{SEM} 2019)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S19-1023",
    doi = "10.18653/v1/S19-1023",
    pages = "205--211",
    abstract = "Word representations trained on text reproduce human implicit bias related to gender, race and age. Methods have been developed to remove such bias. Here, we present results that show that human stereotypes exist even for much more nuanced judgments such as personality, for a variety of person identities beyond the typically legally protected attributes and that these are similarly captured in word representations. Specifically, we collected human judgments about a person{'}s Big Five personality traits formed solely from information about the occupation, nationality or a common noun description of a hypothetical person. Analysis of the data reveals a large number of statistically significant stereotypes in people. We then demonstrate the bias captured in lexical representations is statistically significantly correlated with the documented human bias. Our results, showing bias for a large set of person descriptors for such nuanced traits put in doubt the feasibility of broadly and fairly applying debiasing methods and call for the development of new methods for auditing language technology systems and resources.",
}


@article{agarwal2020entity,
    title={Entity-switched datasets: An approach to auditing the in-domain robustness of named entity recognition models},
    author={Agarwal, Oshin and Yang, Yinfei and Wallace, Byron C and Nenkova, Ani},
    journal={arXiv preprint arXiv:2004.04123},
    year={2020}
}


@article{agarwal2020entity,
    title={Entity linking via dual and cross-attention encoders},
    author={Agarwal, Oshin and Bikel, Daniel M},
    journal={arXiv preprint arXiv:2004.03555},
    year={2020}
}


@article{Agarwal_2022,
    title={Towards Robust Named Entity Recognition via Temporal Domain Adaptation and Entity Context Understanding}, 
    volume={36}, 
    url={https://ojs.aaai.org/index.php/AAAI/article/view/21570}, 
    DOI={10.1609/aaai.v36i11.21570}, 
    abstract={Named Entity Recognition models perform well on benchmark datasets but fail to generalize well even in the same domain. The goal of my thesis is to quantify the degree of in-domain generalization in NER, probe models for entity name vs. context learning and finally improve their robustness, focusing on the recognition of ethnically diverse entities and new entities over time when the models are deployed.}, 
    number={11}, 
    journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
    author={Agarwal, Oshin}, 
    year={2022}, 
    month={Jun.}, 
    pages={12866-12867} 
}
~         
